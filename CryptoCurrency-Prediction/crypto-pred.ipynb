{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 13:54:41.306058: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734337481.350263   53342 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734337481.363085   53342 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-16 13:54:41.459229: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "from collections import deque\n",
    "import random \n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import numpy as np \n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRYPTO_TO_PREDICT = \"LTC-USD\"\n",
    "SEQ_LEN = 60  \n",
    "FUTURE_PERIOD_PREDICT = 3  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    df = df.drop(\"future\", axis=1)  \n",
    "    \n",
    "    for col in df.columns:  \n",
    "        if col != \"target\":  \n",
    "            df[col] = df[col].pct_change()  \n",
    "            df.dropna(inplace=True)  \n",
    "            df[col] = preprocessing.scale(df[col].values)  \n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    sequential_data = []\n",
    "    prev_days = deque(maxlen=SEQ_LEN)\n",
    "\n",
    "    for i in df.values:  \n",
    "        prev_days.append([n for n in i[:-1]]) \n",
    "        if len(prev_days) == SEQ_LEN:  \n",
    "            sequential_data.append([np.array(prev_days), i[-1]])\n",
    "    \n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    buys = []\n",
    "    sells = []\n",
    "    \n",
    "    for seq, target in sequential_data:  \n",
    "        if target == 0:  \n",
    "            sells.append([seq, target]) \n",
    "        elif target == 1:  \n",
    "            buys.append([seq, target])  \n",
    "            \n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    \n",
    "    lower = min(len(buys), len(sells))    \n",
    "    \n",
    "    buys=buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "            \n",
    "    sequential_data = buys+sells \n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "        \n",
    "    return np.array(X), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53342/1336114630.py:21: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method=\"ffill\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 77922  || validation: 3860\n",
      "Dont buys: 38961, buys: 38961\n",
      "VALIDATION Dont buys: 1930, buys: 1930\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.DataFrame()\n",
    "\n",
    "cryptos = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"] \n",
    "for crypto in cryptos:  \n",
    "\n",
    "    # crypto = cryptos.split('.csv')[0]  \n",
    "    dataset = f'data/{crypto}.csv'  \n",
    "    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])  \n",
    "\n",
    "    # rename volume and close \n",
    "    df.rename(columns={\"close\": f\"{crypto}_close\", \"volume\": f\"{crypto}_volume\"}, inplace=True)\n",
    "\n",
    "    df.set_index(\"time\", inplace=True)  # set time as index \n",
    "    df = df[[f\"{crypto}_close\", f\"{crypto}_volume\"]]  \n",
    "\n",
    "    if len(merged_df)==0: \n",
    "        merged_df = df  \n",
    "    else:  \n",
    "        merged_df = merged_df.join(df)\n",
    "\n",
    "merged_df.fillna(method=\"ffill\", inplace=True)  \n",
    "\n",
    "merged_df['future'] = merged_df[f'{CRYPTO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "merged_df['target'] = list(map(classify, merged_df[f'{CRYPTO_TO_PREDICT}_close'], merged_df['future']))\n",
    "\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "times = sorted(merged_df.index.values)\n",
    "last_5pct = sorted(merged_df.index.values)[-int(0.05*len(times))]\n",
    "\n",
    "validation_merged_df = merged_df[(merged_df.index >= last_5pct)]\n",
    "merged_df = merged_df[(merged_df.index < last_5pct)]\n",
    "\n",
    "X_train, y_train = preprocess_df(merged_df)\n",
    "X_val, y_val = preprocess_df(validation_merged_df)\n",
    "\n",
    "print(f\"train data: {len(X_train)}  || validation: {len(X_val)}\")\n",
    "print(f\"Dont buys: {y_train.count(0)}, buys: {y_train.count(1)}\")\n",
    "print(f\"VALIDATION Dont buys: {y_val.count(0)}, buys: {y_val.count(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN-MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734337488.755277   53342 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3620 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/anson/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/home/anson/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10  \n",
    "BATCH_SIZE = 64  \n",
    "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\" \n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "tensorBoard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "filepath = \"models/RNN_Final-{epoch:02d}-{val_accuracy:.3f}.keras\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (77922, 60, 8), y_train shape: 77922\n",
      "X_val shape: (3860, 60, 8), y_val shape: 3860\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {len(y_train)}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {len(y_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734337493.426130   53457 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1217/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4952 - loss: 0.7586\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52073, saving model to models/RNN_Final-01-0.521.keras\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 35ms/step - accuracy: 0.4952 - loss: 0.7586 - val_accuracy: 0.5207 - val_loss: 0.6921\n",
      "Epoch 2/10\n",
      "\u001b[1m1217/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5135 - loss: 0.6936\n",
      "Epoch 2: val_accuracy improved from 0.52073 to 0.54326, saving model to models/RNN_Final-02-0.543.keras\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.5135 - loss: 0.6936 - val_accuracy: 0.5433 - val_loss: 0.6887\n",
      "Epoch 3/10\n",
      "\u001b[1m1217/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5301 - loss: 0.6899\n",
      "Epoch 3: val_accuracy improved from 0.54326 to 0.55052, saving model to models/RNN_Final-03-0.551.keras\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.5301 - loss: 0.6899 - val_accuracy: 0.5505 - val_loss: 0.6816\n",
      "Epoch 4/10\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5443 - loss: 0.6872\n",
      "Epoch 4: val_accuracy improved from 0.55052 to 0.55337, saving model to models/RNN_Final-04-0.553.keras\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 33ms/step - accuracy: 0.5443 - loss: 0.6872 - val_accuracy: 0.5534 - val_loss: 0.6874\n",
      "Epoch 5/10\n",
      "\u001b[1m1217/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5504 - loss: 0.6849\n",
      "Epoch 5: val_accuracy did not improve from 0.55337\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 35ms/step - accuracy: 0.5504 - loss: 0.6849 - val_accuracy: 0.5355 - val_loss: 0.6896\n",
      "Epoch 6/10\n",
      "\u001b[1m1217/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5517 - loss: 0.6847\n",
      "Epoch 6: val_accuracy improved from 0.55337 to 0.56036, saving model to models/RNN_Final-06-0.560.keras\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - accuracy: 0.5517 - loss: 0.6847 - val_accuracy: 0.5604 - val_loss: 0.6803\n",
      "Epoch 7/10\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5612 - loss: 0.6830\n",
      "Epoch 7: val_accuracy improved from 0.56036 to 0.56114, saving model to models/RNN_Final-07-0.561.keras\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.5612 - loss: 0.6830 - val_accuracy: 0.5611 - val_loss: 0.6803\n",
      "Epoch 8/10\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5592 - loss: 0.6827\n",
      "Epoch 8: val_accuracy did not improve from 0.56114\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 35ms/step - accuracy: 0.5592 - loss: 0.6827 - val_accuracy: 0.5539 - val_loss: 0.6875\n",
      "Epoch 9/10\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5662 - loss: 0.6804\n",
      "Epoch 9: val_accuracy did not improve from 0.56114\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.5662 - loss: 0.6804 - val_accuracy: 0.5518 - val_loss: 0.6804\n",
      "Epoch 10/10\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5634 - loss: 0.6805\n",
      "Epoch 10: val_accuracy improved from 0.56114 to 0.56295, saving model to models/RNN_Final-10-0.563.keras\n",
      "\u001b[1m1218/1218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.5634 - loss: 0.6805 - val_accuracy: 0.5630 - val_loss: 0.6765\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[tensorBoard, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
