{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "from collections import deque\n",
    "import random \n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import numpy as np \n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRYPTO_TO_PREDICT = \"BTC-USD\" # use any from data/\n",
    "SEQ_LEN = 60  \n",
    "FUTURE_PERIOD_PREDICT = 3  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    df = df.drop(\"future\", axis=1)  \n",
    "    \n",
    "    for col in df.columns:  \n",
    "        if col != \"target\":  \n",
    "            df[col] = df[col].pct_change()  \n",
    "            df.dropna(inplace=True)  \n",
    "            df[col] = preprocessing.scale(df[col].values)  \n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    sequential_data = []\n",
    "    prev_days = deque(maxlen=SEQ_LEN)\n",
    "\n",
    "    for i in df.values:  \n",
    "        prev_days.append([n for n in i[:-1]]) \n",
    "        if len(prev_days) == SEQ_LEN:  \n",
    "            sequential_data.append([np.array(prev_days), i[-1]])\n",
    "    \n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    buys = []\n",
    "    sells = []\n",
    "    \n",
    "    for seq, target in sequential_data:  \n",
    "        if target == 0:  \n",
    "            sells.append([seq, target]) \n",
    "        elif target == 1:  \n",
    "            buys.append([seq, target])  \n",
    "            \n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    \n",
    "    lower = min(len(buys), len(sells))    \n",
    "    \n",
    "    buys=buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "            \n",
    "    sequential_data = buys+sells \n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "        \n",
    "    return np.array(X), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53342/1336114630.py:21: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method=\"ffill\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 83156  || validation: 4478\n",
      "Dont buys: 41578, buys: 41578\n",
      "VALIDATION Dont buys: 2239, buys: 2239\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.DataFrame()\n",
    "\n",
    "cryptos = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"] \n",
    "for crypto in cryptos:  \n",
    "\n",
    "    # crypto = cryptos.split('.csv')[0]  \n",
    "    dataset = f'data/{crypto}.csv'  \n",
    "    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])  \n",
    "\n",
    "    # rename volume and close \n",
    "    df.rename(columns={\"close\": f\"{crypto}_close\", \"volume\": f\"{crypto}_volume\"}, inplace=True)\n",
    "\n",
    "    df.set_index(\"time\", inplace=True)  # set time as index \n",
    "    df = df[[f\"{crypto}_close\", f\"{crypto}_volume\"]]  \n",
    "\n",
    "    if len(merged_df)==0: \n",
    "        merged_df = df  \n",
    "    else:  \n",
    "        merged_df = merged_df.join(df)\n",
    "\n",
    "merged_df.fillna(method=\"ffill\", inplace=True)  \n",
    "\n",
    "merged_df['future'] = merged_df[f'{CRYPTO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "merged_df['target'] = list(map(classify, merged_df[f'{CRYPTO_TO_PREDICT}_close'], merged_df['future']))\n",
    "\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "times = sorted(merged_df.index.values)\n",
    "last_5pct = sorted(merged_df.index.values)[-int(0.05*len(times))]\n",
    "\n",
    "validation_merged_df = merged_df[(merged_df.index >= last_5pct)]\n",
    "merged_df = merged_df[(merged_df.index < last_5pct)]\n",
    "\n",
    "X_train, y_train = preprocess_df(merged_df)\n",
    "X_val, y_val = preprocess_df(validation_merged_df)\n",
    "\n",
    "print(f\"train data: {len(X_train)}  || validation: {len(X_val)}\")\n",
    "print(f\"Dont buys: {y_train.count(0)}, buys: {y_train.count(1)}\")\n",
    "print(f\"VALIDATION Dont buys: {y_val.count(0)}, buys: {y_val.count(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN-MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anson/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/home/anson/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10  \n",
    "BATCH_SIZE = 64  \n",
    "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\" \n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "tensorBoard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "filepath = \"models/RNN_Final-{epoch:02d}-{val_accuracy:.3f}.keras\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (83156, 60, 8), y_train shape: 83156\n",
      "X_val shape: (4478, 60, 8), y_val shape: 4478\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {len(y_train)}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {len(y_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1299/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5213 - loss: 0.7502\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55895, saving model to models/RNN_Final-01-0.559.keras\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 34ms/step - accuracy: 0.5213 - loss: 0.7501 - val_accuracy: 0.5590 - val_loss: 0.6830\n",
      "Epoch 2/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5631 - loss: 0.6827\n",
      "Epoch 2: val_accuracy improved from 0.55895 to 0.56655, saving model to models/RNN_Final-02-0.567.keras\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 33ms/step - accuracy: 0.5631 - loss: 0.6827 - val_accuracy: 0.5665 - val_loss: 0.6771\n",
      "Epoch 3/10\n",
      "\u001b[1m1299/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5686 - loss: 0.6806\n",
      "Epoch 3: val_accuracy did not improve from 0.56655\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 33ms/step - accuracy: 0.5686 - loss: 0.6806 - val_accuracy: 0.5659 - val_loss: 0.6798\n",
      "Epoch 4/10\n",
      "\u001b[1m1299/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5769 - loss: 0.6763\n",
      "Epoch 4: val_accuracy improved from 0.56655 to 0.58039, saving model to models/RNN_Final-04-0.580.keras\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 33ms/step - accuracy: 0.5769 - loss: 0.6763 - val_accuracy: 0.5804 - val_loss: 0.6734\n",
      "Epoch 5/10\n",
      "\u001b[1m1299/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5835 - loss: 0.6728\n",
      "Epoch 5: val_accuracy did not improve from 0.58039\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 33ms/step - accuracy: 0.5835 - loss: 0.6728 - val_accuracy: 0.5724 - val_loss: 0.6756\n",
      "Epoch 6/10\n",
      "\u001b[1m1299/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5884 - loss: 0.6705\n",
      "Epoch 6: val_accuracy did not improve from 0.58039\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - accuracy: 0.5884 - loss: 0.6705 - val_accuracy: 0.5741 - val_loss: 0.6748\n",
      "Epoch 7/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5934 - loss: 0.6687\n",
      "Epoch 7: val_accuracy did not improve from 0.58039\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - accuracy: 0.5934 - loss: 0.6687 - val_accuracy: 0.5690 - val_loss: 0.6795\n",
      "Epoch 8/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5963 - loss: 0.6656\n",
      "Epoch 8: val_accuracy did not improve from 0.58039\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 33ms/step - accuracy: 0.5963 - loss: 0.6656 - val_accuracy: 0.5732 - val_loss: 0.6845\n",
      "Epoch 9/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6029 - loss: 0.6619\n",
      "Epoch 9: val_accuracy did not improve from 0.58039\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 33ms/step - accuracy: 0.6029 - loss: 0.6619 - val_accuracy: 0.5748 - val_loss: 0.6774\n",
      "Epoch 10/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6138 - loss: 0.6539\n",
      "Epoch 10: val_accuracy did not improve from 0.58039\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - accuracy: 0.6138 - loss: 0.6539 - val_accuracy: 0.5596 - val_loss: 0.7063\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[tensorBoard, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
