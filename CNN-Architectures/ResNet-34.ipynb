{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM76QqT1D8i3uHCIxlU52/w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ResNet-34 Architecture\n","\n","ResNet-34, short for Residual Network with 34 layers, is a deep convolutional neural network (CNN) designed to address the vanishing gradient problem that hampers the training of deep networks. Introduced by Kaiming He et al. in their paper [\"Deep Residual Learning for Image Recognition\"](https://arxiv.org/abs/1512.03385), ResNet-34 utilizes \"skip connections\" or \"residual connections\" which allow for easier gradient flow through the network.\n","\n","## Key Features\n","\n","### Residual Blocks\n","\n","Instead of learning the underlying mapping, residual blocks learn the residuals (or the difference) between the input and output. This is done by introducing shortcut connections that skip one or more layers.\n","\n","A residual block typically has the following structure:\n","- Two 3x3 convolutional layers.\n","- Batch normalization (BN) after each convolutional layer.\n","- ReLU activation function after each BN.\n","- A shortcut connection that adds the input of the block to the output.\n","\n","### Skip Connections\n","\n","These connections bypass one or more layers by performing identity mapping and then adding the output to the skipped layerâ€™s output. This helps mitigate the vanishing gradient problem by allowing gradients to flow directly through the network.\n","\n","### Network Depth and Layer Composition\n","\n","ResNet-34 is composed of 34 layers, which include:\n","- **Convolutional Layers**: Perform feature extraction by applying filters to the input.\n","- **Pooling Layers**: Reduce the spatial dimensions (height and width) of the input, keeping the depth the same.\n","- **Fully Connected Layers**: Perform classification tasks based on the extracted features.\n","\n","### Layer Breakdown\n","\n","1. **Initial Convolution and Pooling**:\n","   - 1 Convolution layer with 64 filters of size 7x7, stride 2.\n","   - 1 MaxPooling layer with size 3x3, stride 2.\n","\n","2. **Residual Blocks**:\n","   - **Conv2_x**: 3 blocks, each with 2 convolutional layers of size 3x3 and 64 filters.\n","   - **Conv3_x**: 4 blocks, each with 2 convolutional layers of size 3x3 and 128 filters. The first block uses a convolutional layer with stride 2 to reduce spatial dimensions.\n","   - **Conv4_x**: 6 blocks, each with 2 convolutional layers of size 3x3 and 256 filters. The first block uses a convolutional layer with stride 2 to reduce spatial dimensions.\n","   - **Conv5_x**: 3 blocks, each with 2 convolutional layers of size 3x3 and 512 filters. The first block uses a convolutional layer with stride 2 to reduce spatial dimensions.\n","\n","3. **Final Layers**:\n","   - 1 Average Pooling layer with size 7x7.\n","   - 1 Fully Connected layer with 1000 neurons (for classification into 1000 classes).\n","\n","### Detailed Architecture\n","\n"],"metadata":{"id":"Ye5SGBmBxxj5"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"K0R071SxvbTK","executionInfo":{"status":"ok","timestamp":1722279176012,"user_tz":-330,"elapsed":484,"user":{"displayName":"Anson Antony S","userId":"12303217689544018303"}}},"outputs":[],"source":["# CREATE A RESIDUAL UNIT LAYER\n","from functools import partial\n","import tensorflow as tf\n","\n","DefaultConv2d = partial(tf.keras.layers.Conv2D, kernel_size=3, strides=1, padding=\"same\",\n","                        kernel_initializer=\"he_normal\", use_bias=False)"]},{"cell_type":"code","source":["class ResidualUnit(tf.keras.layers.Layer):\n","  def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n","    super().__init__(**kwargs)\n","    self.activation = tf.keras.activations.get(activation)\n","    self.main_layers = [\n","        DefaultConv2d(filters, strides=strides),\n","        tf.keras.layers.BatchNormalization(),\n","        self.activation,\n","        DefaultConv2d(filters),\n","        tf.keras.layers.BatchNormalization()\n","    ]\n","\n","    self.skip_layers = []\n","    if strides > 1:\n","      self.skip_layers = [\n","          DefaultConv2d(filters, kernel_size=1, strides=strides),\n","          tf.keras.layers.BatchNormalization()\n","      ]\n","\n","      def call(self, inputs):\n","        Z = inputs\n","        for layer in self.main_layers:\n","          Z = layer(Z)\n","\n","        skip_Z = inputs\n","        for layer in self.skip_layers:\n","          skip_Z = layer(skip_Z)\n","\n","        return self.activation(Z + skip_Z)"],"metadata":{"id":"nIfO0khWxqmo","executionInfo":{"status":"ok","timestamp":1722279178040,"user_tz":-330,"elapsed":3,"user":{"displayName":"Anson Antony S","userId":"12303217689544018303"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# BUILDING RESNET-34 USING SEQUENTIAL\n","\n","model = tf.keras.Sequential([\n","    DefaultConv2d(64, kernel_size=7, strides=2, input_shape=[224, 224, 3]),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Activation(\"relu\"),\n","    tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\")\n","])\n","\n","prev_filters = 64\n","for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n","  strides = 1 if filters == prev_filters else 2\n","  model.add(ResidualUnit(filters, strides=strides))\n","  prev_filters = filters\n","\n","model.add(tf.keras.layers.GlobalAvgPool2D())\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"],"metadata":{"id":"8kqSkaMn0AEm","executionInfo":{"status":"ok","timestamp":1722279221707,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anson Antony S","userId":"12303217689544018303"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"u4p4dtwW1ar7"},"execution_count":null,"outputs":[]}]}