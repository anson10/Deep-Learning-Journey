{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet Architecture\n",
    "\n",
    "We are ready to describe the overall architecture of our CNN. As depicted in Figure 2, the network consists of eight layers with weights. The first five layers are convolutional, and the remaining three layers are fully connected. The output of the last fully connected layer is fed to a 1000-way softmax, which produces a distribution over the 1000 class labels. Our network maximizes the multinomial logistic regression objective, equivalent to maximizing the average log-probability of the correct label under the prediction distribution across training cases.\n",
    "\n",
    "## Layers\n",
    "\n",
    "### Convolutional Layers\n",
    "\n",
    "1. **First Convolutional Layer**\n",
    "    - Filters the 224×224×3 input image with 96 kernels of size 11×11×3\n",
    "    - Stride of 4 pixels\n",
    "2. **Second Convolutional Layer**\n",
    "    - Takes the response-normalized and pooled output of the first convolutional layer\n",
    "    - Filters with 256 kernels of size 5×5×48\n",
    "3. **Third Convolutional Layer**\n",
    "    - Connected to all kernel maps in the second layer\n",
    "    - 384 kernels of size 3×3×256\n",
    "4. **Fourth Convolutional Layer**\n",
    "    - 384 kernels of size 3×3×192\n",
    "5. **Fifth Convolutional Layer**\n",
    "    - 256 kernels of size 3×3×192\n",
    "\n",
    "### Fully Connected Layers\n",
    "\n",
    "1. **First Fully Connected Layer**\n",
    "    - 4096 neurons\n",
    "2. **Second Fully Connected Layer**\n",
    "    - 4096 neurons\n",
    "3. **Third Fully Connected Layer**\n",
    "    - 1000-way softmax, producing a distribution over the 1000 class labels\n",
    "\n",
    "## Connections\n",
    "\n",
    "- **Convolutional Layers**\n",
    "  - Kernels of the second, fourth, and fifth convolutional layers are connected only to those kernel maps in the previous layer which reside on the same GPU\n",
    "  - Kernels of the third convolutional layer are connected to all kernel maps in the second layer\n",
    "\n",
    "- **Fully Connected Layers**\n",
    "  - Neurons in the fully connected layers are connected to all neurons in the previous layer\n",
    "\n",
    "## Additional Components\n",
    "\n",
    "- **Response-normalization Layers**\n",
    "  - Follow the first and second convolutional layers\n",
    "\n",
    "- **Max-pooling Layers**\n",
    "  - Follow both response-normalization layers and the fifth convolutional layer\n",
    "\n",
    "- **ReLU Non-linearity**\n",
    "  - Applied to the output of every convolutional and fully connected layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
    " Conv2D, MaxPooling2D,BatchNormalization\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# (3) Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11),\\\n",
    " strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling \n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation before passing it to the next layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Passing it to a dense layer\n",
    "model.add(Flatten())\n",
    "# 1st Dense Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Dense Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(17))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 55, 55, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 27, 27, 96)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 27, 27, 96)        384       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 17, 17, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 8, 8, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 6, 6, 384)         0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 6, 6, 384)         1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 4, 384)         0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 4, 4, 384)         1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 1, 1, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 1, 1, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              1052672   \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 4096)              16384     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 4096)              16384     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1000)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 1000)              4000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 17)                17017     \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 17)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28096769 (107.18 MB)\n",
      "Trainable params: 28075633 (107.10 MB)\n",
      "Non-trainable params: 21136 (82.56 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"spare_categorical_entropy\",\n",
    "    optimizer=\"Adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(X_train,y_train, validation_data=(X_val, y_val), epochs=20)\n",
    "model.save(\"AlexNet_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
