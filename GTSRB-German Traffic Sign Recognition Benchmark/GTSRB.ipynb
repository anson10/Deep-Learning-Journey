{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING NECESSARY MODULES\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STORING DATA AND LABELS\n",
    "# dataset link is provided in README.md\n",
    "import os\n",
    " \n",
    "data = []\n",
    "labels = []\n",
    " \n",
    "classes = 43   #GTSRB has 43 classes\n",
    " \n",
    "cwd = os.getcwd()\n",
    " \n",
    "#print(cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING THE IMAGE\n",
    "\n",
    "for img in range(classes):\n",
    "    path = os.path.join(cwd, 'Train', str(img))\n",
    "    #print(path)\n",
    "    images = os.listdir(path)\n",
    "    #print(images)\n",
    "    for i in images:\n",
    "        try:\n",
    "            image = Image.open(path + '/' + i)\n",
    "            image = image.resize((32,32))\n",
    "            image = np.array(image)\n",
    "            data.append(image)\n",
    "            labels.append(img)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE LABELS AND DATA FOR FUTURE USES\n",
    "# os.mkdir('trained_data')\n",
    "\n",
    "np.save('trained_data/data', data)\n",
    "np.save('trained_data/labels', labels)\n",
    "# np.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE NP DATA AND LABELS\n",
    "\n",
    "data = np.load('trained_data/data.npy')\n",
    "labels = np.load('trained_data/labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT THE DATA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELS TO ONE-HOT ENCODING\n",
    "\n",
    "'''This code is converting the labels in y_train and y_test to one-hot encoded vectors with 43 classes. '''\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 43)\n",
    "y_test = to_categorical(y_test, 43)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Architecture\n",
    "\n",
    "This model is a Convolutional Neural Network (CNN) designed for image classification tasks. Below is a summary of the model architecture:\n",
    "\n",
    "## Layers\n",
    "\n",
    "1. **Conv2D Layer**\n",
    "   - **Filters:** 32\n",
    "   - **Kernel Size:** (5, 5)\n",
    "   - **Activation Function:** ReLU\n",
    "   - **Input Shape:** Same as the input image shape, excluding the batch size (e.g., `(32, 32, 3)` for an RGB image with 32x32 pixels).\n",
    "\n",
    "2. **Conv2D Layer**\n",
    "   - **Filters:** 32\n",
    "   - **Kernel Size:** (5, 5)\n",
    "   - **Activation Function:** ReLU\n",
    "\n",
    "3. **MaxPooling2D Layer**\n",
    "   - **Pool Size:** (2, 2)\n",
    "\n",
    "4. **Dropout Layer**\n",
    "   - **Rate:** 0.25\n",
    "\n",
    "5. **Conv2D Layer**\n",
    "   - **Filters:** 64\n",
    "   - **Kernel Size:** (3, 3)\n",
    "   - **Activation Function:** ReLU\n",
    "\n",
    "6. **Conv2D Layer**\n",
    "   - **Filters:** 64\n",
    "   - **Kernel Size:** (3, 3)\n",
    "   - **Activation Function:** ReLU\n",
    "\n",
    "7. **MaxPooling2D Layer**\n",
    "   - **Pool Size:** (2, 2)\n",
    "\n",
    "8. **Dropout Layer**\n",
    "   - **Rate:** 0.25\n",
    "\n",
    "9. **Flatten Layer**\n",
    "   - Converts the 2D matrix into a 1D vector for the dense layer.\n",
    "\n",
    "10. **Dense Layer**\n",
    "    - **Units:** 256\n",
    "    - **Activation Function:** ReLU\n",
    "\n",
    "11. **Dropout Layer**\n",
    "    - **Rate:** 0.5\n",
    "\n",
    "12. **Dense Layer**\n",
    "    - **Units:** 43 (number of classes)\n",
    "    - **Activation Function:** Softmax (used for multi-class classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING TENSORBOARD\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING THE MODEL\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='relu',input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=((2,2))),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(43, activation=\"softmax\")                           \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=15, validation_data=(X_test,y_test), callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=logs/fit\n",
    "\n",
    "'''Use this in the terminal to analyse your model'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITOUT TENSORBOARD\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATING OUR MODEL\n",
    "\n",
    "def test_model(test_csv):\n",
    "    y_test = pd.read_csv(test_csv)\n",
    "    label = y_test['ClassId'].values\n",
    "    imgs = y_test['Path'].values\n",
    "    data = []\n",
    "    \n",
    "    for img in imgs:\n",
    "        image = Image.open(img)\n",
    "        image = image.resize((32,32))\n",
    "        data.append(np.array(image))\n",
    "    X_test = np.array(data)\n",
    "    return X_test, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, label = test_model('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Find the class with the highest probability\n",
    "y_pred = np.argmax(y_pred_prob, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"GTSRB.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK ACCURACY\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"GTSRB.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSES USED IN THIS DATASET\n",
    "classes = { 0:'Speed limit (20km/h)',\n",
    "            1:'Speed limit (30km/h)', \n",
    "            2:'Speed limit (50km/h)', \n",
    "            3:'Speed limit (60km/h)', \n",
    "            4:'Speed limit (70km/h)', \n",
    "            5:'Speed limit (80km/h)', \n",
    "            6:'End of speed limit (80km/h)', \n",
    "            7:'Speed limit (100km/h)', \n",
    "            8:'Speed limit (120km/h)', \n",
    "            9:'No passing', \n",
    "            10:'No passing veh over 3.5 tons', \n",
    "            11:'Right-of-way at intersection', \n",
    "            12:'Priority road', \n",
    "            13:'Yield', \n",
    "            14:'Stop', \n",
    "            15:'No vehicles', \n",
    "            16:'Veh > 3.5 tons prohibited', \n",
    "            17:'No entry', \n",
    "            18:'General caution', \n",
    "            19:'Dangerous curve left', \n",
    "            20:'Dangerous curve right', \n",
    "            21:'Double curve', \n",
    "            22:'Bumpy road', \n",
    "            23:'Slippery road', \n",
    "            24:'Road narrows on the right', \n",
    "            25:'Road work', \n",
    "            26:'Traffic signals', \n",
    "            27:'Pedestrians', \n",
    "            28:'Children crossing', \n",
    "            29:'Bicycles crossing', \n",
    "            30:'Beware of ice/snow',\n",
    "            31:'Wild animals crossing', \n",
    "            32:'End speed + passing limits', \n",
    "            33:'Turn right ahead', \n",
    "            34:'Turn left ahead', \n",
    "            35:'Ahead only', \n",
    "            36:'Go straight or right', \n",
    "            37:'Go straight or left', \n",
    "            38:'Keep right', \n",
    "            39:'Keep left', \n",
    "            40:'Roundabout mandatory', \n",
    "            41:'End of no passing', \n",
    "            42:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_img(img):\n",
    "    data = []\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((32,32))\n",
    "    data.append(np.array(image))\n",
    "    X_test = np.array(data)\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "    return image, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot,prediction = test_img('Test/00010.png')\n",
    "s = [str(i) for i in prediction] \n",
    "a = int(\"\".join(s)) \n",
    "print(\"Predicted traffic sign is: \", classes[a])\n",
    "plt.imshow(plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
