{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ORGANISATION\n",
    "\n",
    "The images of cats and dogs are currently mixed in the `train` and `test1` directories. Before training the model, you need to separate these images into standard subdirectories for cats and dogs within each directory (`train` and `test1`). This organization is crucial for the proper labeling and training of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE SEPERATE FOLDERS\n",
    "# !mkdir -p train/train/cats train/train/dogs test1/test1/cats test1/test1/dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVE IMAGES TO RESPECTIVE FOLDERS\n",
    "# Dataset can be downloaded from link provided in README.md\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "train_dir = \"train/train\"\n",
    "test_dir = \"test1/test1\"\n",
    "\n",
    "def move_files(src_dir, dest_cat_dir, dest_dog_dir):\n",
    "    for filename in os.listdir(src_dir):\n",
    "        if filename.startswith('cat'):\n",
    "            shutil.move(os.path.join(src_dir, filename), os.path.join(dest_cat_dir, filename))\n",
    "        elif filename.startswith('dog'):\n",
    "            shutil.move(os.path.join(src_dir, filename), os.path.join(dest_dog_dir, filename))\n",
    "            \n",
    "move_files(train_dir,'train/train/dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING THE IMAGES\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Define class labels\n",
    "classes = {'cats': 0, 'dogs': 1}\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Preprocessing the images\n",
    "for class_name, label in classes.items():\n",
    "    path = os.path.join(cwd, 'train/train', class_name)\n",
    "    images = os.listdir(path)\n",
    "    \n",
    "    for image_file in images:\n",
    "        try:\n",
    "            image = Image.open(os.path.join(path, image_file))\n",
    "            image = image.resize((32, 32))  # Resize image to 32x32\n",
    "            image = np.array(image)         # Convert image to numpy array\n",
    "            data.append(image)              # Append image to data list\n",
    "            labels.append(label)            # Append label to labels list\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_file}: {e}\")\n",
    "\n",
    "# Convert lists to numpy arrays for better handling\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # USING TENSORFLOW FOR DATA ORGANISATION\n",
    "# import tensorflow as tf\n",
    "# tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# data = []\n",
    "# labels = []\n",
    "\n",
    "# cwd = os.getcwd()\n",
    "\n",
    "# classes = {'cats': 0, 'dogs': 1}\n",
    "\n",
    "# for class_name, label in classes.items():\n",
    "#     path = os.path.join(cwd, 'train/train', class_name)\n",
    "#     images = os.listdir(path)\n",
    "    \n",
    "#     for image_file in images:\n",
    "#         try:\n",
    "#             # Load the image using TensorFlow\n",
    "#             image_path = os.path.join(path, image_file)\n",
    "#             image = tf.io.read_file(image_path)\n",
    "#             image = tf.image.decode_jpeg(image, channels=3)\n",
    "#             image = tf.image.resize(image, [32, 32])  # Resize image to 32x32\n",
    "#             image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "            \n",
    "#             data.append(image)\n",
    "#             labels.append(label)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing image {image_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE LABELS AND DATA FOR FUTURE USES\n",
    "\n",
    "# os.mkdir('trained_data')\n",
    "\n",
    "np.save('trained_data/data', data)\n",
    "np.save('trained_data/labels', labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('trained_data/data.npy')\n",
    "labels = np.load('trained_data/labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT THE DATA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LABELS TO ONE-HOT ENCODING\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING A BASIC CNN MODEL\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu',input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),    \n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),    \n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),    \n",
    "    tf.keras.layers.Dense(2, activation=\"softmax\")                           \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=30,\n",
    "                    validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATING OUR MODEL USING TEST IMAGES\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "test_folder = 'test1/test1'\n",
    "image_size = (32,32)\n",
    "\n",
    "test_images = []\n",
    "\n",
    "for img_name in sorted(os.listdir(test_folder)):\n",
    "    img_path = os.path.join(test_folder, img_name)\n",
    "    \n",
    "    img = load_img(img_path, target_size=image_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    test_images.append(img_array)\n",
    "    \n",
    "    \n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classes = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCURACY CHECK\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "# classes = {'cats': 0, 'dogs': 1}\n",
    "classes = [0, 1]\n",
    "\n",
    "\n",
    "def test_img(img):\n",
    "    data = []\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((32,32))\n",
    "    data.append(np.array(image))\n",
    "    X_val = np.array(data)\n",
    "    y_pred = np.argmax(model.predict(X_val), axis=-1)\n",
    "    return image, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot,prediction = test_img('test1/test1/22.jpg')\n",
    "s = [str(i) for i in prediction] \n",
    "a = int(\"\".join(s)) \n",
    "print(\"Predicted photo is: \", classes[a])\n",
    "plt.imshow(plot)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
