{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLayer:\n",
    "    def __init__(self, input_shape, kernel_size, depth):\n",
    "        input_depth, input_height, input_width = input_shape\n",
    "        self.depth = depth\n",
    "        self.input_shape = input_shape\n",
    "        self.input_depth = input_depth\n",
    "        self.kernel_size = kernel_size\n",
    "        self.output_shape = (depth, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "        self.kernels_shape = (depth, input_depth, kernel_size, kernel_size)\n",
    "        self.kernels = np.random.randn(*self.kernels_shape) * 0.1\n",
    "        self.biases = np.random.randn(*self.output_shape) * 0.1  # Changed shape of biases\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = np.zeros((input.shape[0], *self.output_shape))\n",
    "        for b in range(input.shape[0]):  # Iterate over batch size\n",
    "            for d in range(self.depth):\n",
    "                for c in range(self.input_depth):\n",
    "                    self.output[b, d] += signal.correlate2d(input[b, c], self.kernels[d, c], mode='valid')\n",
    "                # Adding biases, now with correct shape\n",
    "                self.output[b, d] += self.biases[d]\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        kernels_gradient = np.zeros(self.kernels_shape)\n",
    "        input_gradient = np.zeros((self.input.shape[0], *self.input_shape))\n",
    "        for b in range(output_gradient.shape[0]):  # Iterate over batch size\n",
    "            for d in range(self.depth):\n",
    "                for c in range(self.input_depth):\n",
    "                    kernels_gradient[d, c] += signal.correlate2d(self.input[b, c], output_gradient[b, d], mode='valid')\n",
    "                    input_gradient[b, c] += signal.convolve2d(output_gradient[b, d], self.kernels[d, c], mode='full')\n",
    "        self.kernels -= learning_rate * kernels_gradient / output_gradient.shape[0]\n",
    "        self.biases -= learning_rate * np.mean(output_gradient, axis=0)\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size, output_size) * 0.1\n",
    "        self.biases = np.random.randn(output_size) * 0.1\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.dot(input, self.weights) + self.biases\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        input_gradient = np.dot(output_gradient, self.weights.T)\n",
    "        weights_gradient = np.dot(self.input.T, output_gradient)\n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.biases -= learning_rate * np.mean(output_gradient, axis=0)\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.maximum(0, input)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return output_gradient * (self.input > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network setup\n",
    "cnn_layer = CNNLayer(input_shape=(1, 28, 28), kernel_size=3, depth=16)\n",
    "relu = ReLU()\n",
    "flatten_layer = lambda x: x.reshape(x.shape[0], -1)\n",
    "dense_layer = DenseLayer(16 * 26 * 26, num_classes)  # 16 filters, 26x26 output from CNN\n",
    "softmax = Softmax()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "        x_batch = x_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        conv_output = cnn_layer.forward(x_batch)\n",
    "        relu_output = relu.forward(conv_output)\n",
    "        flattened_output = flatten_layer(relu_output)\n",
    "        dense_output = dense_layer.forward(flattened_output)\n",
    "        softmax_output = softmax.forward(dense_output)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = categorical_cross_entropy(y_batch, softmax_output)\n",
    "        print(f\"Epoch {epoch+1}, Batch {i//batch_size+1}, Loss: {loss}\")\n",
    "\n",
    "        # Backward pass\n",
    "        loss_grad = categorical_cross_entropy_prime(y_batch, softmax_output)\n",
    "        dense_grad = dense_layer.backward(loss_grad, learning_rate)\n",
    "        flattened_grad = dense_grad.reshape(relu_output.shape)\n",
    "        relu_grad = relu.backward(flattened_grad, learning_rate)\n",
    "        conv_grad = cnn_layer.backward(relu_grad, learning_rate)\n",
    "\n",
    "# Evaluation loop (batched for efficiency)\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(0, len(x_test), batch_size):\n",
    "    x_batch = x_test[i:i+batch_size]\n",
    "    y_batch = y_test[i:i+batch_size]\n",
    "    \n",
    "    conv_output = cnn_layer.forward(x_batch)\n",
    "    relu_output = relu.forward(conv_output)\n",
    "    flattened_output = flatten_layer(relu_output)\n",
    "    dense_output = dense_layer.forward(flattened_output)\n",
    "    softmax_output = softmax.forward(dense_output)\n",
    "    \n",
    "    predictions = np.argmax(softmax_output, axis=1)\n",
    "    correct += np.sum(predictions == np.argmax(y_batch, axis=1))\n",
    "    total += len(y_batch)\n",
    "\n",
    "print(f\"Accuracy: {correct / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py31",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
